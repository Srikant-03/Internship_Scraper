# ğŸ¤– AI/ML Internship Radar
### *Your personal robot that hunts down AI internships while you sleep.*

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://python.org)
[![Flask](https://img.shields.io/badge/flask-3.x-green.svg)](https://flask.palletsprojects.com)
[![Playwright](https://img.shields.io/badge/playwright-stealth-blueviolet.svg)](https://playwright.dev)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## ï¿½ The Problem

You're a CS/AI student trying to land an internship for summer 2026.

So you open 17 tabs â€” LinkedIn, Internshala, Naukri, Unstop, some obscure university portal â€” spend 3 hours copy-pasting, and realize half the listings are from 2024.

**There's a better way.**

---

## ï¿½ What This Does

This project is a **fully automated web scraping system** that:

- ğŸ•·ï¸ **Scrapes 60+ platforms simultaneously** â€” India AND worldwide
- ğŸ§  **Filters by actual AI/ML relevance** â€” not just "software" jobs
- ğŸš« **Auto-rejects closed, expired, and past-year listings** â€” no 2024 garbage slipping through
- ğŸ“Š **Scores every listing from 0â€“100** based on your profile
- ï¿½ï¸ **Streams everything to a beautiful dashboard** at `http://localhost:5000`
- â° **Runs daily at 8 AM automatically** (set it, forget it)

You click one button. The robot does the rest.

---

## ï¿½ The Dashboard

It looks like something Bloomberg would build:

- ğŸŒ **Region Tabs** â€” Everything / ğŸ‡®ğŸ‡³ India / ğŸŒ Global / ğŸ“¡ Remote â€” click to instantly switch
- ğŸ”¥ **Match Score Badges** â€” Glowing green means high AI/ML relevance. Red means meh.
- âš¡ **Live Log Terminal** â€” Watch the scraper work in real-time right inside the browser
- ğŸ—‘ï¸ **Clear Database Button** â€” Red trash icon wipes everything so you can start 100% fresh

Cards are sorted and rendered using CSS Grid `order` properties â€” which means **zero flickering**, even with 300+ listings live-updating every 4 seconds. Butter smooth.

---

## âš ï¸ But Wait â€” Some Sites Are Sneaky

LinkedIn, Naukri, and Unstop have bot blockers. So the scraper:

1. Opens these browsers **visibly** (not headless) so you can see what's happening
2. Shows you a glowing orange **"Action Required"** banner in the dashboard if a CAPTCHA appears
3. Waits **45 seconds** for you to solve it (or it auto-skips and moves on)
4. You click **Done** â†’ banner disappears â†’ scraper resumes silently

It's like pair-programming with a robot.

---

## ï¿½ï¸ Where It Scrapes (60+ Sources)

### ğŸ‡®ğŸ‡³ India
| Platform | How | Notes |
|----------|-----|-------|
| **Internshala** | Playwright stealth | India's #1 internship platform |
| **Unstop** | Playwright headless=False | Scans for "closed" tags â€” won't waste your time |
| **Naukri.com** | Playwright headless=False | India's largest job board |
| **LinkedIn Jobs** | Playwright headless=False | 100+ search configs across Indian cities |
| **Shine / Foundit / Apna / CutShort** | Requests + BS4 | Four aggregators at once |
| **DRDO, ISRO, Govt Labs** | Requests | Real government research portals |
| **DuckDuckGo Dorks** | DDG API | Hidden `.ac.in` and `.res.in` gems |

### ğŸŒ International
| Platform | How | Coverage |
|----------|-----|----------|
| **LinkedIn Jobs** | Playwright | 15+ EU countries, US, Asia |
| **Remotive + WeWorkRemotely** | RSS + Playwright | Best remote AI/ML listings |
| **DuckDuckGo University Search** | DDG API | **54 search queries** â€” see list below |
| **BigTech Careers** | Requests | Google, Meta, Microsoft, Apple, Amazon |
| **Niche AI Boards** | Requests | ML-specific boards you've never heard of |

### ğŸ“ University & Research Lab Discovery

The university scraper fires **54 live DuckDuckGo searches** every run. No hardcoded links. It dynamically discovers current positions at:

ğŸ‡®ğŸ‡³ `IIT, IISc, IIIT, TIFR, DRDO, ISRO`
ğŸ‡©ğŸ‡ª `DAAD RISE, Max Planck, TU Munich, ETH Zurich, EPFL`
ğŸ‡¬ğŸ‡§ `Oxford, Cambridge, UCL, Imperial`
ğŸ‡ºğŸ‡¸ `MIT, Stanford, CMU, Berkeley, Cornell, NSF REU, DOE SULI`
ğŸŒ `OpenAI, DeepMind, Anthropic, Google DeepMind, Meta FAIR, NVIDIA`
ğŸ‡¨ğŸ‡¦ `Mitacs, Mila, Vector Institute, UBC`
ğŸ‡¸ğŸ‡¬ `NUS, NTU, A*STAR, AI Singapore`
ğŸŒ `CERN, ESA, KAUST, Technion, KAIST, RIKEN AIP, CSIRO`

Every run = fresh results. Zero maintenance.

---

## âš™ï¸ How the Filtering Works (The Smart Part)

### ğŸ”‘ AI/ML Keyword Gate
Every listing must contain at least one of **50+ AI/ML terms** to even get in the door:
`machine learning` / `deep learning` / `computer vision` / `LLM` / `generative AI` / `NLP` / `transformers` / `reinforcement learning` / `AI research` and more.

And if the title says `senior`, `5+ years`, `manager`, `PhD required`, or `full-time` â€” **auto-rejected.** You're looking for internships, not a job for someone with a decade of experience.

### ğŸ“… Past Year Defense
Aggregator sites often surface old 2024/2025 listings in their search results. The filter dynamically reads `datetime.now()`, computes the current target year, and then **physically scans the raw listing text** for any stale year string. If it finds `2024` or `2025` hiding in there â€” the card is shredded before it ever hits your screen.

### ğŸ—“ï¸ Summer Date NLP
- Listings must start **on or after May 20** of the upcoming summer
- But terms like `"immediately"`, `"rolling"`, `"ASAP"`, or `"flexible"` are always allowed â€” because a good opportunity isn't date-dependent
- Powered by `dateparser`, a real NLP date extraction library

### ğŸ’° Stipend Check
- **India**: Minimum â‚¹5,000/month (or unspecified = OK)
- **International**: Any compensation is fine
- Explicit `"Unpaid"` or `0` always filtered out

---

## ï¿½ï¸ How to Set It Up (Actually Simple)

**You need:** Python 3.9+ and Google Chrome. That's it.

```bash
# 1. Clone the project
git clone https://github.com/YOUR_USERNAME/ai-ml-internship-radar.git
cd ai-ml-internship-radar/internship_scraper

# 2. Create virtual environment
python -m venv venv
venv\Scripts\activate      # Windows
source venv/bin/activate   # Mac/Linux

# 3. Install everything
pip install -r requirements.txt
playwright install chromium

# 4. Run it
python app.py
```

Open **http://localhost:5000** â†’ click **"Run Scraper Now"** â†’ go make tea â˜•

---

## ğŸ® Using the Dashboard

**Buttons in the top-right corner:**

| Button | What it does |
|--------|-------------|
| ğŸ”„ Refresh | Reload the current data from CSV |
| ğŸ—‘ï¸ Trash (red) | Wipe the entire database and start fresh |
| â„¹ï¸ Info | Open the usage guide modal |

**Sidebar filters** let you drill down by:
- ğŸŒ Location (India / Remote / Global)
- ğŸ’µ Stipend bracket (Any / Paid / >â‚¹10K / >â‚¹20K / >â‚¹50K)
- ğŸ›ï¸ Org type (Company / Institution / Government)
- ğŸ”¬ Role type (Research Core / Applied Engineering)
- ğŸ“¡ Source platform (per-source dropdown)

**Match Score legend:**
- ğŸŸ¢ **â‰¥80** â€” Dream listing. Apply immediately.
- ğŸŸ¡ **60â€“79** â€” Good match. Worth a look.
- ğŸ”´ **<60** â€” Peripheral. Only if you're desperate.

---

## ğŸ¥· Anti-Bot Tactics

The scraper doesn't act like a robot (ironically). It uses:

- **Playwright Stealth Plugin** â€” patches browser fingerprints, defeats bot detection
- **Random human delays** â€” 1.5â€“4.5 second waits between clicks
- **Rotating User-Agents** â€” realistic Chrome UA strings on Windows/Mac
- **Random scrolling** â€” simulates actually reading the page
- **Visible browser for protected sites** â€” you intervene when needed
- **Exponential backoff retries** â€” fails gracefully on network blips

---

## ğŸ—‚ï¸ Project Structure (If You Want to Poke Around)

```
internship_scraper/
â”œâ”€â”€ app.py                 â† Flask server + all API endpoints
â”œâ”€â”€ scraper.py             â† Orchestrator: runs all scrapers in sequence
â”œâ”€â”€ filters.py             â† The brain: NLP keyword + date + stipend filters
â”œâ”€â”€ output_handler.py      â† Deduplication engine + CSV writer
â”œâ”€â”€ scraper_utils.py       â† Shared tools: delays, headers, stealth args
â”‚
â”œâ”€â”€ sites/
â”‚   â”œâ”€â”€ internshala.py     â† Playwright stealth scraper
â”‚   â”œâ”€â”€ unstop.py          â† Playwright + closed-card detection
â”‚   â”œâ”€â”€ naukri.py          â† CAPTCHA-aware visible browser
â”‚   â”œâ”€â”€ linkedin.py        â† 100+ config LinkedIn public jobs scraper
â”‚   â”œâ”€â”€ rss_feeds.py       â† Remotive + WeWorkRemotely RSS
â”‚   â”œâ”€â”€ government.py      â† DRDO, ISRO, govt portals
â”‚   â”œâ”€â”€ misc_india.py      â† Shine, Foundit, Apna, CutShort
â”‚   â”œâ”€â”€ international.py   â† WeWorkRemotely Playwright
â”‚   â”œâ”€â”€ bigtech.py         â† FAANG career pages
â”‚   â”œâ”€â”€ niche.py           â† AI-specific job boards
â”‚   â”œâ”€â”€ search_engine.py   â† 8 DuckDuckGo dork queries (geo-filtered)
â”‚   â””â”€â”€ universities.py    â† 54 DDG searches, global university discovery
â”‚
â”œâ”€â”€ templates/index.html   â† The dashboard
â”œâ”€â”€ static/style.css       â† Bloomberg dark aesthetic, glassmorphism
â”œâ”€â”€ static/script.js       â† Live filtering, polling, XSS-safe card rendering
â”‚
â”œâ”€â”€ internships.csv        â† The database (gitignored)
â”œâ”€â”€ internships_log.json   â† Scraper memory for deduplication (gitignored)
â”œâ”€â”€ scraper_run.log        â† What the scraper did (gitignored)
â””â”€â”€ scraper_errors.log     â† What went wrong (gitignored)
```

---

## ï¿½ Trouble? Read This First.

**"No listings showing for Naukri / Unstop"**
â†’ A CAPTCHA appeared and the timer ran out. Just run the scraper again and solve it when the browser pops up. You have **45 seconds**.

**"LinkedIn is showing 0 results"**
â†’ LinkedIn probably showed a sign-in popup. Close it manually when the visible browser opens.

**"DuckDuckGo returned nothing"**
â†’ DDG rate-limits aggressive requests. Wait 5 minutes and try again. Or increase the delay in `scraper_utils.py` â†’ `human_delay()`.

**"Port 5000 is already in use"**
â†’ Change the last line in `app.py` to `app.run(debug=True, port=5001)`.

**"Clear button did nothing"**
â†’ The scraper was probably still running. Wait for it to finish first, then clear.

---

## ğŸ“Š Output Format

Every discovered internship is saved to `internships.csv` with:

| Field | Description |
|-------|-------------|
| `id` | MD5 hash for deduplication |
| `role_title` | Job title |
| `company_name` | Company or institution |
| `location` | City / Country |
| `location_type` | `India` / `International` / `Remote` |
| `stipend` | Raw text (e.g., "â‚¹15,000/month") |
| `stipend_numeric` | Parsed number |
| `apply_link` | Direct URL |
| `source_platform` | Which scraper found it |
| `date_scraped` | When it was discovered |
| `org_type` | `Company` / `Institution` / `Government` |
| `role_type` | `Research` / `Applied` |
| `match_score` | 0â€“100 relevance score |

---

## â° Running on a Schedule

**Windows (Task Scheduler):**
```powershell
schtasks /create /tn "AI Radar" /tr "python C:\path\to\internship_scraper\scraper.py" /sc DAILY /st 08:00
```

**Mac/Linux (Cron):**
```bash
0 8 * * * cd /path/to/internship_scraper && python scraper.py >> cron.log 2>&1
```

---

## ğŸ“œ License

MIT â€” do whatever you want with it.

---

## âš ï¸ Disclaimer

This was built for personal use to find internships. Please don't hammer servers at high frequency or use this commercially. The rate limiting is there for a reason â€” be a decent human to the websites you're scraping.
