# ðŸ¤– AI/ML Internship Radar

> **A production-ready, fully automated web scraper that discovers AI/ML internship opportunities from 60+ global sources â€” India and Worldwide â€” and presents them in a stunning real-time dashboard.**

[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://python.org)
[![Flask](https://img.shields.io/badge/flask-3.x-green.svg)](https://flask.palletsprojects.com)
[![Playwright](https://img.shields.io/badge/playwright-stealth-blueviolet.svg)](https://playwright.dev)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## ðŸ“¸ Dashboard Preview

The dashboard features a Bloomberg-inspired dark UI with:
- ðŸŒ **Region Tab Bar** â€” instantly filter by Everything / ðŸ‡®ðŸ‡³ India / ðŸŒ Global / ðŸ“¡ Remote
- ðŸ“Š **Match Score Badges** â€” every listing scored out of 100 for AI/ML relevance
- âš¡ **Real-time Logs** â€” view live scraper activity as it runs
- ðŸŽ›ï¸ **Smart Sidebar Filters** â€” Source, Location Type, Stipend, Org Type, Role Level

---

## ðŸŽ¯ What It Does

This system automatically:
1. **Scrapes 60+ platforms** for AI/ML internship listings worldwide
2. **Filters** by AI/ML relevance, stipend thresholds, and summer date windows
3. **Deduplicates** across all sources using content hashing
4. **Scores** every listing with a 0â€“100 AI/ML match score
5. **Presents** results in a live web dashboard at `http://localhost:5000`
6. **Auto-schedules** daily scrapes at 8:00 AM

---

## ðŸ” Data Sources (60+ Platforms)

### ðŸ‡®ðŸ‡³ India Platforms
| Source | Method | Notes |
|--------|--------|-------|
| **Internshala** | Playwright (stealth) | Largest Indian internship platform |
| **Unstop** | Playwright (headless=False) | Tech-focused, may require CAPTCHA |
| **Naukri.com** | Playwright (headless=False) | India's largest job board |
| **LinkedIn Jobs** | Playwright (headless=False) | 7 topics Ã— 5 Indian cities |
| **Shine.com** | Requests + BeautifulSoup | Mid-level jobs board |
| **Foundit (Monster India)** | Requests + BeautifulSoup | - |
| **Apna** | Playwright | Blue-collar + tech roles |
| **CutShort** | Requests | Startup-focused |
| **DRDO / Government Labs** | Requests | Govt research portals |
| **Search Engine (DDG Dorks)** | DuckDuckGo API | Hidden opportunities, .ac.in sites |

### ðŸŒ International Platforms
| Source | Method | Coverage |
|--------|--------|----------|
| **LinkedIn Jobs** | Playwright | Worldwide, 15+ European countries, US cities, Canada, Asia |
| **Remotive.com RSS** | RSS Feed | AI/ML remote internships |
| **WeWorkRemotely RSS** | RSS Feed | Remote programming & data science |
| **WeWorkRemotely** | Playwright | AI/ML keyword search |
| **Universities (Dynamic)** | DuckDuckGo (54 queries) | See below â†“ |
| **BigTech Careers** | Requests | Google, Meta, Microsoft, Apple, Amazon |
| **Niche AI Boards** | Requests | ML-specific job boards |
| **Aggregators** | Requests | Indeed-style aggregators |

### ðŸŽ“ University & Research Lab Discovery (Dynamic)

The university scraper runs **54 targeted DuckDuckGo searches** that refresh on every run â€” no hardcoded lists:

| Region | Examples |
|--------|---------|
| ðŸ‡®ðŸ‡³ India | IIT, IISc, IIIT, TIFR, DRDO, ISRO, ISI |
| ðŸ‡«ðŸ‡® Nordic | **Aalto University**, FCAI, KTH, Chalmers, DTU, NTNU, Helsinki |
| ðŸ‡©ðŸ‡ª Germany/DACH | DAAD RISE, Max Planck, TU Munich, RWTH, ETH Zurich, EPFL, IST Austria |
| ðŸ‡¬ðŸ‡§ UK | Oxford, Cambridge, UCL, Imperial, Edinburgh |
| ðŸ‡«ðŸ‡·ðŸ‡³ðŸ‡± France/NL | Inria, TU Delft, CWI Amsterdam |
| ðŸ‡¨ðŸ‡³ China | Tsinghua, Peking, SJTU, USTC, ZJU, Fudan, CAS |
| ðŸ‡¸ðŸ‡¬ Singapore | NUS, NTU, A*STAR, AI Singapore |
| ðŸ‡¯ðŸ‡µðŸ‡°ðŸ‡· Japan/Korea | RIKEN AIP, NII, KAIST, NAVER AI Lab, Samsung |
| ðŸ‡¦ðŸ‡º Australia | ANU, Melbourne, CSIRO Data61 |
| ðŸ‡¨ðŸ‡¦ Canada | Mitacs, Vector Institute, Mila, UBC, McGill |
| ðŸ‡ºðŸ‡¸ USA | MIT, Stanford, CMU, Berkeley, Cornell, UW, Georgia Tech, NSF REU |
| ðŸ‡ºðŸ‡¸ US National Labs | Oak Ridge, Argonne, PNNL, Sandia, DOE SULI |
| ðŸŒ Global AI Labs | OpenAI, DeepMind, Anthropic, Meta FAIR, Google, NVIDIA, Adobe, IBM, AI2 |
| ðŸŒ Misc | CERN, ESA, KAUST (UAE), Technion, AIMS Africa, USP Brazil |

---

## ðŸ—ï¸ Project Structure

```
internship_scraper/
â”œâ”€â”€ app.py                    # Flask web server + Socket.IO for live logs
â”œâ”€â”€ scraper.py                # Orchestrator â€” runs all scrapers
â”œâ”€â”€ filters.py                # AI/ML keyword filter, stipend validator, date parser
â”œâ”€â”€ output_handler.py         # CSV append with deduplication
â”œâ”€â”€ scraper_utils.py          # Human delays, Playwright stealth args
â”‚
â”œâ”€â”€ sites/                    # Individual scraper modules
â”‚   â”œâ”€â”€ internshala.py        # Playwright stealth â€” 400+ listings
â”‚   â”œâ”€â”€ unstop.py             # Playwright headless=False, 7 search URLs
â”‚   â”œâ”€â”€ naukri.py             # Playwright headless=False (CAPTCHA-aware)
â”‚   â”œâ”€â”€ linkedin.py           # LinkedIn PUBLIC jobs page â€” 80+ search configs
â”‚   â”œâ”€â”€ rss_feeds.py          # Remotive.com + WeWorkRemotely RSS
â”‚   â”œâ”€â”€ government.py         # DRDO, ISRO, Govt India portals
â”‚   â”œâ”€â”€ misc_india.py         # Shine, Foundit, Apna, CutShort
â”‚   â”œâ”€â”€ international.py      # WeWorkRemotely Playwright scraper
â”‚   â”œâ”€â”€ bigtech.py            # Google, Meta, Microsoft, Apple, Amazon careers
â”‚   â”œâ”€â”€ niche.py              # Niche AI job boards + aggregators
â”‚   â”œâ”€â”€ search_engine.py      # DuckDuckGo dork search (8 query patterns)
â”‚   â””â”€â”€ universities.py       # Dynamic DDG search â€” 54 queries, global unis
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ index.html            # Dashboard HTML (Phosphor Icons + custom CSS)
â”‚
â”œâ”€â”€ static/
â”‚   â”œâ”€â”€ style.css             # Bloomberg dark UI, glassmorphism, animations
â”‚   â”œâ”€â”€ script.js             # Live filtering, region tabs, real-time logs
â”‚   â””â”€â”€ favicon.ico
â”‚
â”œâ”€â”€ internships.csv           # Output data file (gitignored)
â”œâ”€â”€ internships_log.json      # Run history + metadata (gitignored)
â”œâ”€â”€ scraper_run.log           # Full activity log (gitignored)
â””â”€â”€ scraper_errors.log        # Error log (gitignored)
```

---

## âš™ï¸ How Filtering Works

### 1. AI/ML Keyword Filter (`filters.py`)
A listing must contain **at least one** of 50+ AI/ML keywords:
- Core: `machine learning`, `deep learning`, `neural network`, `NLP`
- Applied: `computer vision`, `reinforcement learning`, `LLM`, `generative AI`
- Tools: `PyTorch`, `TensorFlow`, `transformers`, `scikit-learn`, `pandas`
- Roles: `data science intern`, `AI engineer`, `ML research`

### 2. Stipend Filter
- **India listings**: Minimum â‚¹5,000/month (or unpaid is OK)
- **International listings**: Any stipend (or unpaid research is OK)
- Filter respects INR vs USD currencies automatically

### 3. Date Filter (`parse_summer_dates`)
- Summer internships must start **on or after May 20**
- Flexible terms like `"Immediately"`, `"ASAP"`, `"Rolling"`, `"Flexible"` are **always allowed**

### 4. Match Scoring (`calculate_match_score`)
Each listing gets a 0â€“100 score based on:
- Number of AI/ML keywords found in title + description
- Institution type (Research institution gets bonus)
- Stipend level relative to tier

---

## ðŸš€ Setup & Installation

### Prerequisites
- Python 3.9+
- Google Chrome (for Playwright)
- Git

### 1. Clone the Repository
```bash
git clone https://github.com/YOUR_USERNAME/ai-ml-internship-radar.git
cd ai-ml-internship-radar/internship_scraper
```

### 2. Create Virtual Environment
```bash
python -m venv venv

# Windows
venv\Scripts\activate

# macOS/Linux
source venv/bin/activate
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Install Playwright Browsers
```bash
playwright install chromium
```

### 5. Run the App
```bash
python app.py
```

Open **http://localhost:5000** in your browser.

---

## ðŸŽ® Usage Guide

### Running the Dashboard
```bash
python app.py
```
The dashboard auto-loads the last scrape results. Click **"Run Scraper Now"** to trigger a fresh scrape.

### Running the Scraper Manually
```bash
# Full scrape (all sources)
python scraper.py

# Dry-run (doesn't save to CSV, just logs)
python scraper.py --dry-run

# Scrape a specific source only
python scraper.py --source internshala
python scraper.py --source linkedin
python scraper.py --source universities
python scraper.py --source naukri --dry-run
```

### Available `--source` Values
| Source Key | Description |
|-----------|-------------|
| `internshala` | Internshala scraper |
| `unstop` | Unstop scraper |
| `naukri` | Naukri.com scraper |
| `linkedin` | LinkedIn Jobs direct scraper (80+ configs) |
| `remotive` | Remotive RSS feed |
| `weworkremotely` | WeWorkRemotely RSS feed |
| `government` | Indian government labs |
| `shine` | Shine.com |
| `foundit` | Foundit.in |
| `apna` | Apna.co |
| `cutshort` | CutShort.io |
| `international` | WeWorkRemotely Playwright |
| `bigtech` | FAANG + big tech careers |
| `niche` | Niche AI boards |
| `aggregators` | Job aggregators |
| `universities` | Global university DDG search |
| `search` | DuckDuckGo dork search |

### Scheduling (Auto-run Daily)

**Windows Task Scheduler:**
```powershell
schtasks /create /tn "AI Radar Scraper" /tr "python C:\path\to\internship_scraper\scraper.py" /sc DAILY /st 08:00
```

**Linux/macOS Cron:**
```bash
0 8 * * * cd /path/to/internship_scraper && python scraper.py >> cron.log 2>&1
```

---

## ðŸ–¥ï¸ Dashboard Features

### Region Tab Bar
Filter instantly by choosing a region tab above the cards:
| Tab | Filter |
|-----|--------|
| ðŸŒ Everything | All listings |
| ðŸ‡®ðŸ‡³ India | Indian locations only |
| ðŸŒ Global / Abroad | International listings |
| ðŸ“¡ Remote | Fully remote positions |

### Sidebar Filters
- **Search**: Text search across role, company, and skills
- **Location Type**: ðŸŒ All / ðŸ“¡ Remote / ðŸ‡®ðŸ‡³ India / ðŸŒ Global
- **Stipend (INR)**: Any / Paid Only / >â‚¹10K / >â‚¹20K / >â‚¹50K / Unpaid
- **Source Platform**: Per-source dropdown (dynamically populated)
- **Organization Type**: All / Company / Institution / Government
- **Role Level**: All / Research Core / Applied Engineering

### Match Score Badges
- ðŸŸ¢ **High Score (80â€“100)**: Strong AI/ML role, research focus, competitive stipend
- ðŸŸ¡ **Medium Score (60â€“79)**: Relevant role, moderate AI/ML alignment
- ðŸ”´ **Low Score (<60)**: Peripherally relevant

---

## ðŸ”’ Anti-Blocking Features

The scraper uses multiple layers of anti-detection:

1. **Playwright Stealth Plugin** â€” patches browser fingerprints
2. **Human-like delays** â€” random `time.sleep()` between 1â€“5 seconds per action
3. **Realistic User-Agents** â€” Chrome 122 Windows 10 UA strings
4. **Random scrolling** â€” simulates reading behavior
5. **Visible Browser Mode** â€” Naukri, Unstop, and LinkedIn run with `headless=False` so **you can manually solve CAPTCHAs** if they appear (45-second window)
6. **Tenacity retry** â€” automatic retry with exponential backoff on failures

---

## ðŸ› ï¸ Configuration

Key settings are in `filters.py`:

```python
# Minimum stipend for Indian internships (INR/month)
MIN_INDIA_STIPEND = 5000

# AI/ML keywords required in title/description
KEYWORDS = ["machine learning", "deep learning", "NLP", ...]

# Summer date filter â€” internships must start from:
SUMMER_START = datetime(current_year, 5, 20)

# Flex terms always allowed regardless of date
ALLOW_TERMS = ["immediately", "asap", "rolling", "flexible", "ongoing"]
```

---

## ðŸ“¦ Requirements

```
flask
flask-socketio
playwright
playwright-stealth
beautifulsoup4
lxml
requests
ddgs                # DuckDuckGo search API
duckduckgo-search   # Legacy fallback
feedparser          # RSS parsing
pandas
loguru              # Structured logging
tenacity            # Retry logic
schedule            # Daily scheduling
```

---

## ðŸ”§ Troubleshooting

### "No listings found" for Naukri / Unstop
These sites use CAPTCHAs. When the browser window opens, solve the CAPTCHA within:
- **Naukri**: 45 seconds
- **Unstop**: 20 seconds

### LinkedIn shows 0 results
LinkedIn may show a sign-in modal. The scraper waits 8â€“12 seconds after page load â€” close the popup manually when it appears.

### DuckDuckGo returning 0 results
DDG has rate limits. Add a longer delay in `scraper_utils.py` `human_delay()` or wait a few minutes before re-running.

### Port 5000 already in use
Change the port in `app.py`:
```python
socketio.run(app, host="0.0.0.0", port=5001, debug=False)
```

---

## ðŸ“„ Output Format

Results are saved to `internships.csv` with these columns:

| Column | Description |
|--------|-------------|
| `id` | MD5 hash â€” used for deduplication |
| `company_name` | Company or institution name |
| `role_title` | Job title |
| `location` | City/Country |
| `location_type` | `India` / `International` / `Remote` |
| `duration` | Internship duration |
| `stipend` | Raw stipend text |
| `stipend_numeric` | Numeric value (INR or USD) |
| `stipend_currency` | `INR` or `USD` |
| `required_skills` | Skills mentioned |
| `application_deadline` | Deadline date |
| `apply_link` | Direct application URL |
| `source_platform` | Which scraper found it |
| `date_scraped` | Date of discovery |
| `org_type` | `Company` / `Institution` / `Government` |
| `role_type` | `Research` / `Applied` |
| `match_score` | 0â€“100 AI/ML relevance score |

---

## ðŸ¤ Contributing

1. Fork the repository
2. Add a new scraper in `sites/yoursite.py`
3. Register it in `scraper.py`'s `scrapers` dict
4. Submit a pull request

**Adding a new scraper:** Follow the pattern in any existing `sites/*.py` file â€” return a list of dicts matching the output schema above.

---

## ðŸ“œ License

MIT License â€” free to use, modify, and distribute.

---

## âš ï¸ Disclaimer

This tool is for **personal educational use** only. Respect each website's `robots.txt` and Terms of Service. The included rate limiting and human-like delays help ensure respectful usage. Do not use this tool for commercial scraping or at high frequencies.
